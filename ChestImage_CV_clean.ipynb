{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imporing Libraries"
      ],
      "metadata": {
        "id": "DwqiT28EPlNH"
      },
      "id": "DwqiT28EPlNH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99bdaa73",
      "metadata": {
        "id": "99bdaa73"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import keras.backend as K\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation,  AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "my_devices = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
        "tf.config.experimental.set_visible_devices(devices= my_devices, device_type='GPU')\n",
        "\n",
        "seed = 240\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eff9a9c",
      "metadata": {
        "id": "4eff9a9c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")\n",
        "    # print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pulling the Data From GitHub\n"
      ],
      "metadata": {
        "id": "34RzDECQv2sz"
      },
      "id": "34RzDECQv2sz"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hrmoradi/Workshop_data # goes to your cotent folder"
      ],
      "metadata": {
        "id": "7ccXgkJsv8L4"
      },
      "id": "7ccXgkJsv8L4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8e8726e2",
      "metadata": {
        "id": "8e8726e2"
      },
      "source": [
        "# Import the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66f08d2d",
      "metadata": {
        "id": "66f08d2d"
      },
      "outputs": [],
      "source": [
        "# Take all file names in different directory\n",
        "base_directory     = '/content/Workshop_data/chest_xray/'\n",
        "\n",
        "train_pne_dir = os.listdir(base_directory +'/train/PNEUMONIA/')\n",
        "train_nor_dir = os.listdir(base_directory +'/train/NORMAL/')\n",
        "\n",
        "val_pne_dir  = os.listdir(base_directory +'/val/PNEUMONIA/')\n",
        "val_nor_dir  = os.listdir(base_directory +'/val/NORMAL/')\n",
        "\n",
        "test_pne_dir = os.listdir(base_directory +'/test/PNEUMONIA/')\n",
        "test_nor_dir = os.listdir(base_directory +'/test/NORMAL/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de453082",
      "metadata": {
        "id": "de453082"
      },
      "source": [
        "## Check the size and pixel ranges of pictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c916207a",
      "metadata": {
        "id": "c916207a"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "# ! pip install imageio\n",
        "import imageio\n",
        "\n",
        "for i in range(0,2):\n",
        "    pic= train_nor_dir[i]\n",
        "    pic = imageio.imread(base_directory+'/train/NORMAL/' + pic)\n",
        "    plt.figure(figsize = (2,2))\n",
        "    plt.imshow(pic, cmap='gray')\n",
        "    print()\n",
        "    print('Type of the image : ' , type(pic))\n",
        "    print('Shape of the image : {}'.format(pic.shape))\n",
        "    print('Dimension of Image {}'.format(pic.ndim))\n",
        "    print('dtype: ', pic.dtype)\n",
        "    print('Maximum RGB value in this image {}'.format(pic.max()))\n",
        "    print('Minimum RGB value in this image {}'.format(pic.min()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "809d2251",
      "metadata": {
        "id": "809d2251"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "n_rows = 3\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        pic= train_nor_dir[index]\n",
        "        pic = imageio.imread(base_directory+'/train/NORMAL/' + pic)\n",
        "        plt.imshow(pic, cmap='gray')\n",
        "        plt.axis('off')\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "# plt.save_fig('ChestImages')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e4506c5",
      "metadata": {
        "id": "8e4506c5"
      },
      "source": [
        "# Import and preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1053ce81",
      "metadata": {
        "id": "1053ce81"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "color_mode=\"grayscale\" # \"rgb\"\n",
        "img_dims = 224\n",
        "batch_size = 32\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1/255.0, zoom_range=0.3, vertical_flip=True, validation_split=0.2)\n",
        "val_gen = ImageDataGenerator(rescale=1/255.0)\n",
        "test_gen = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "    directory= base_directory+\"/train/\",\n",
        "    target_size=(img_dims, img_dims),\n",
        "    # color_mode = color_mode,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",  \n",
        "    shuffle=True,\n",
        "    subset='training')\n",
        "\n",
        "valid_generator = train_gen.flow_from_directory(\n",
        "    directory= base_directory+\"/val/\",\n",
        "    target_size=(img_dims, img_dims),\n",
        "    # color_mode = color_mode,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=True, \n",
        "    subset='validation')\n",
        "  \n",
        "test_generator = test_gen.flow_from_directory(\n",
        "    directory=base_directory+\"/test/\",\n",
        "    target_size=(img_dims, img_dims),\n",
        "    # color_mode= color_mode,\n",
        "    batch_size=batch_size,  \n",
        "    class_mode='binary',  \n",
        "    shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436baaaa",
      "metadata": {
        "id": "436baaaa"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "train_counter = list(Counter(train_generator.classes).values())\n",
        "val_counter   = list(Counter(valid_generator.classes).values())\n",
        "test_counter  = list(Counter(test_generator.classes).values())\n",
        "\n",
        "summa_dat = pd.DataFrame([train_counter, val_counter, test_counter], columns=('normal', 'pnuemonia'), index = ['train', 'validation', 'test'])\n",
        "print('Frequency of the normal+infected: \\n', summa_dat)\n",
        "summa_dat.plot(kind='bar', title='Frequency of the normal+infected')\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f035655c",
      "metadata": {
        "id": "f035655c"
      },
      "source": [
        "# A basic CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33e9b5a9",
      "metadata": {
        "id": "33e9b5a9"
      },
      "source": [
        "### Creating a basic model using Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfd8672",
      "metadata": {
        "id": "acfd8672"
      },
      "outputs": [],
      "source": [
        "model_1 = keras.Sequential([\n",
        "   Conv2D(64, 3, input_shape=(img_dims,img_dims, 3), activation='relu'),\n",
        "   Conv2D(32, 3, activation='relu'),\n",
        "   MaxPool2D(pool_size=(2,2)),  \n",
        "   Dropout(0.5),    \n",
        "   Flatten(),\n",
        "   Dense(128, activation='relu'),  \n",
        "   Dense(1, activation='sigmoid')\n",
        "])\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c667939",
      "metadata": {
        "id": "6c667939"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model_1, \"basic_model_1.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0846d145",
      "metadata": {
        "id": "0846d145"
      },
      "source": [
        "## Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c93e01",
      "metadata": {
        "id": "08c93e01"
      },
      "outputs": [],
      "source": [
        "model_1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53538434",
      "metadata": {
        "id": "53538434"
      },
      "source": [
        "## Training and Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa856726",
      "metadata": {
        "id": "fa856726"
      },
      "outputs": [],
      "source": [
        "epochs = 7\n",
        "model1_hist = model_1.fit(x=train_generator,\n",
        "                    steps_per_epoch=train_generator.n//batch_size,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=valid_generator.n //batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d280bb05",
      "metadata": {
        "id": "d280bb05"
      },
      "outputs": [],
      "source": [
        "def draw_hist_f(hist):\n",
        "    \n",
        "    pd.DataFrame(hist.history).plot(figsize=(8, 5))\n",
        "    plt.title('Learning curve of the model')\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0, 1)\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.9))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3ef1b8",
      "metadata": {
        "id": "3a3ef1b8"
      },
      "outputs": [],
      "source": [
        "draw_hist_f(model1_hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d65ab3a",
      "metadata": {
        "id": "0d65ab3a"
      },
      "source": [
        "### Evaluate the model on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4cd08a7",
      "metadata": {
        "id": "a4cd08a7"
      },
      "outputs": [],
      "source": [
        "model_1_test = model_1.evaluate(test_generator, steps = test_generator.n//batch_size) # 2 more calls: .predict    .predict_proba. What are the diff?\n",
        "print(model_1.metrics_names)\n",
        "print(model_1_test)\n",
        "print(\"Accuracy = \",model_1_test[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bab1be97",
      "metadata": {
        "id": "bab1be97"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e9b893",
      "metadata": {
        "id": "38e9b893"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eba4c81",
      "metadata": {
        "id": "6eba4c81"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
        "from tensorflow.keras import applications as app\n",
        "\n",
        "# img_input = tf.keras.layers.Input(shape=(img_dims, img_dims,1))\n",
        "# img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])  \n",
        "\n",
        "# tl_model = app.ResNet152V2(input_shape=None, include_top=False, weights='imagenet', input_tensor=img_conc, pooling='avg') # no support for depth 1\n",
        "tl_model = app.ResNet50V2(input_shape=(224,224,3), include_top=False, weights='imagenet') # no support for depth 1\n",
        "# tl_model = app.DenseNet201(input_shape=None,include_top=False, weights='imagenet',input_tensor=img_conc, pooling='avg') # no support for depth 1\n",
        "# tl_model = app.EfficientNetB7(input_shape=None,include_top=False, weights='imagenet',input_tensor=img_conc, pooling='avg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training full model"
      ],
      "metadata": {
        "id": "W81s2sZma1dA"
      },
      "id": "W81s2sZma1dA"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tl_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "tl_full_model = Model(inputs = tl_model.input, outputs = output)\n",
        "# tl_full_model.summary()\n",
        "tl_full_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "tl_full_model_hist = tl_full_model.fit(x=train_generator,\n",
        "                    steps_per_epoch=train_generator.n//batch_size,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=valid_generator.n //batch_size,\n",
        "                    epochs=7,\n",
        "                    callbacks=[early_stopping,lr],\n",
        "                    verbose = 1)\n",
        "\n",
        "tl_full_model = tl_full_model.evaluate(test_generator, steps = test_generator.n//batch_size) # 2 more calls: .predict    .predict_proba. What are the diff?\n",
        "print(\"Accuracy = \",tl_full_model[1])"
      ],
      "metadata": {
        "id": "sI_kZU7R7z6W"
      },
      "id": "sI_kZU7R7z6W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Head"
      ],
      "metadata": {
        "id": "CchPPk8Da4-R"
      },
      "id": "CchPPk8Da4-R"
    },
    {
      "cell_type": "code",
      "source": [
        "tl_freez_model = app.ResNet50V2(input_shape=(224,224,3), include_top=False, weights='imagenet') \n",
        "\n",
        "# Make loaded layers as non-trainable\n",
        "for layer in tl_freez_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = tl_freez_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "# Create model object\n",
        "tl_freez_full_model = Model(inputs = tl_freez_model.input, outputs = output)\n",
        "# tl_freez_full_model.summary()\n",
        "tl_freez_full_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "tl_freez_full_model_hist = tl_freez_full_model.fit(x=train_generator,\n",
        "                    steps_per_epoch=train_generator.n//batch_size,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=valid_generator.n //batch_size,\n",
        "                    epochs=7,\n",
        "                    callbacks=[early_stopping,lr],\n",
        "                    verbose = 1)\n",
        "\n",
        "tl_freez_full_model = tl_freez_full_model.evaluate(test_generator, steps = test_generator.n//batch_size) # 2 more calls: .predict    .predict_proba. What are the diff?\n",
        "print(\"Accuracy = \",tl_freez_full_model[1])\n"
      ],
      "metadata": {
        "id": "Mlp2n7jPCoLi"
      },
      "id": "Mlp2n7jPCoLi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training head + some conv layers"
      ],
      "metadata": {
        "id": "WfdTXf9Ea93v"
      },
      "id": "WfdTXf9Ea93v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bcadcc4",
      "metadata": {
        "id": "2bcadcc4"
      },
      "outputs": [],
      "source": [
        "tl_freez_model = app.ResNet50V2(input_shape=(224,224,3), include_top=False, weights='imagenet') \n",
        "\n",
        "# Make loaded layers as non-trainable\n",
        "for layer in tl_freez_model.layers:\n",
        "  if layer.name == \"conv4_block1_1_conv\":\n",
        "    print(\"found conv4_block1_1_conv\")\n",
        "    break\n",
        "  layer.trainable = False\n",
        "\n",
        "x = tl_freez_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "# Create model object\n",
        "tl_freez_full_model = Model(inputs = tl_freez_model.input, outputs = output)\n",
        "# tl_freez_full_model.summary()\n",
        "tl_freez_full_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "tl_freez_full_model_hist = tl_freez_full_model.fit(x=train_generator,\n",
        "                    steps_per_epoch=train_generator.n//batch_size,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=valid_generator.n //batch_size,\n",
        "                    epochs=7,\n",
        "                    callbacks=[early_stopping,lr],\n",
        "                    verbose = 1)\n",
        "\n",
        "tl_freez_full_model = tl_freez_full_model.evaluate(test_generator, steps = test_generator.n//batch_size) # 2 more calls: .predict    .predict_proba. What are the diff?\n",
        "print(\"Accuracy = \",tl_freez_full_model[1])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}